import os
import feedparser
import anthropic
from pyzotero import zotero
from github import Github
import datetime
import re
import time

# â”€â”€ API Keys (GitHub Secrets) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CLAUDE_API_KEY = os.environ.get("CLAUDE_API_KEY")
ZOTERO_API_KEY = os.environ.get("ZOTERO_API_KEY")
ZOTERO_USER_ID = "19141751"
GITHUB_TOKEN   = os.environ.get("GH_TOKEN")
GITHUB_REPO    = "soomin-umd/soomin-umd.github.io"

# â”€â”€ RSS Feeds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# results=100 â†’ Springer ê¸°ë³¸ 25ê°œ í•œê³„ ìš°íšŒ, ìµœê·¼ 100ê°œê¹Œì§€ ìˆ˜ì§‘
RSS_FEEDS = {
    "Research in Higher Education":
        "https://link.springer.com/search.rss?facet-content-type=Article&facet-journal-id=11162&results=100",
    "Journal of Higher Education":
        "https://www.tandfonline.com/feed/rss/uhej20",
    "Educational Evaluation and Policy Analysis":
        "https://journals.sagepub.com/action/showFeed?jc=epaa&type=etoc&feed=rss",
    "Journal of Policy Analysis and Management":
        "https://onlinelibrary.wiley.com/feed/15206688/most-recent",
}

# â”€â”€ Keywords â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
QUANT_KEYWORDS = [
    "difference-in-differences", "difference in differences",
    r"\bdid\b",                                  # â† ë‹¨ì–´ ê²½ê³„ë¡œ ì˜¤íƒ ë°©ì§€
    "d-i-d", "regression discontinuity", "rdd", "rd design",
    "instrumental variable", "two-stage least squares", "2sls",
    "propensity score", "psm", "matching estimat",
    "panel data", "fixed effects", "random effects",
    "synthetic control", "event study",
    "quasi-experimental", "natural experiment",
    "causal inference", "causal identification",
    r"causal effect",        # "causal effects" ë³µìˆ˜ë„ ë§¤ì¹­
    "multilevel model", "hierarchical linear model", "ols regression",
    "logistic regression", "logit model", "probit model",
    "interrupted time series", "its analysis", "segmented regression",
    "triple difference", "difference-in-difference-in-differences",
    "staggered adoption", "callaway", "sant'anna",
    "heterogeneous treatment",
    "regression model", "multivariate regression",
    "longitudinal", "cross-sectional analysis",
]

K12_KEYWORDS = [
    "k-12", "k12", "elementary school", "middle school",
    "primary school", "secondary school", "kindergarten",
    "grade school", "school district", "preschool", "pre-k",
    "early childhood", "p-12", "p12",
    # "literacy" ì œê±° â†’ higher edì—ì„œë„ ìì£¼ ì“°ì„ (financial literacy ë“±)
]

TITLE_KEYWORDS = [
    "financial aid", "tuition", "selectivity", "equity",
    "access", "enrollment", "college completion",
    "first-generation", "first generation",
    "intergenerational", "mobility",
    "scholarship", "affordability", "student loan",
    "transfer", "retention", "attainment",
    "community college", "four-year", "postsecondary",
    "lower-income", "low-income", "pell",
    "underrepresented", "minority", "racial",
]

def fetch_abstract_from_doi(doi: str) -> str:
    """DOIë¡œ Crossref APIì—ì„œ abstract ê°€ì ¸ì˜¤ê¸° (Zoteroì— abstract ì—†ì„ ë•Œ fallback)"""
    if not doi:
        return ''
    try:
        import urllib.request, json
        url = f"https://api.crossref.org/works/{doi}"
        req = urllib.request.Request(url, headers={'User-Agent': 'LitBot/1.0'})
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = json.loads(resp.read())
            abstract = data.get('message', {}).get('abstract', '')
            # <jats:p> íƒœê·¸ ì œê±°
            abstract = re.sub(r'<[^>]+>', '', abstract).strip()
            return abstract
    except Exception as e:
        print(f"  âš ï¸ Crossref fetch failed: {e}")
        return ''


# â”€â”€ Filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def passes_filter(title: str, abstract: str, debug: bool = False) -> tuple[bool, str]:
    text       = (title + " " + abstract).lower()
    title_text = title.lower()

    # K-12 reject
    for kw in K12_KEYWORDS:
        if kw in text:
            return False, f"K-12 detected: '{kw}'"

    # Quant method match (ì •ê·œì‹ ì§€ì›)
    quant_match = next(
        (kw for kw in QUANT_KEYWORDS if re.search(kw, text)), None
    )

    # Topic keyword in title
    title_match = next(
        (kw for kw in TITLE_KEYWORDS if kw in title_text), None
    )

    if debug:
        print(f"    [DEBUG] quant_match={quant_match} | title_match={title_match}")
        print(f"    [DEBUG] title='{title_text[:80]}'")
        print(f"    [DEBUG] abstract_len={len(abstract)}")

    if not quant_match and not title_match:
        return False, "No quant/topic keyword"

    matched = quant_match or title_match
    return True, f"Match: '{matched}'"


# â”€â”€ Zotero save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_to_zotero(paper: dict):
    zot  = zotero.Zotero(ZOTERO_USER_ID, 'user', ZOTERO_API_KEY)
    item = zot.item_template('journalArticle')
    item['title']            = paper['title']
    item['url']              = paper['link']
    item['publicationTitle'] = paper['journal']
    item['date']             = paper['date']
    item['abstractNote']     = paper['abstract']
    item['tags']             = [
        {'tag': 'auto-imported'},
        {'tag': 'quant-methods'},
        {'tag': 'higher-ed'},
    ]
    zot.create_items([item])
    print("  ğŸ“š Saved to Zotero")


# â”€â”€ Claude summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_summary(paper: dict) -> str:
    client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)
    prompt = f"""Analyze the following higher education paper.
I am a PhD student researching intergenerational educational mobility,
first-generation college students (FGCS), and state financial aid policy.

Title: {paper['title']}
Journal: {paper['journal']}
Date: {paper['date']}
Abstract: {paper['abstract']}

Please write in English using the format below:

## ğŸ“Œ Core Research Question

## ğŸ”¬ Methodology
(Specify identification strategy in detail: DiD, RD, IV, PSM, etc.)

## ğŸ“Š Key Findings
(Include specific numbers/effect sizes if available)

## ğŸ’¡ Relevance to My Research
(Connect to intergenerational mobility, FGCS, and/or state financial aid policy)

## â­ Key Quote Worth Citing (verbatim from abstract)
"""
    response = client.messages.create(
        model="claude-opus-4-6",
        max_tokens=1200,
        messages=[{"role": "user", "content": prompt}],
    )
    return response.content[0].text


# â”€â”€ GitHub post â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sanitize_title(title: str) -> str:
    """YAML front matterì—ì„œ ë”°ì˜´í‘œ ì¶©ëŒ ë°©ì§€"""
    return title.replace('"', "'").replace(':', ' -')


def post_to_github(paper: dict, summary: str, source_label: str = "RSS"):
    g     = Github(GITHUB_TOKEN)
    repo  = g.get_repo(GITHUB_REPO)
    today = datetime.date.today()
    slug  = re.sub(r'[^a-z0-9\-]', '',
                   paper['title'][:40].lower().replace(' ', '-'))
    filename = f"_posts/{today}-litnote-{slug}.md"

    safe_title = sanitize_title(paper['title'])

    content = f"""---
title: "[LitNote] {safe_title}"
date: {today}
categories: [Literature Notes]
tags: [quant-methods, higher-ed, auto-summary]
source: {source_label}
---

> **Journal:** {paper['journal']}
> **Published:** {paper['date']}
> **Source:** [Full Article]({paper['link']})

---

{summary}

---
*ğŸ¤– Auto-generated using Claude API | Source: {source_label}*
"""
    try:
        repo.create_file(
            path=filename,
            message=f"Auto LitNote: {paper['title'][:50]}",
            content=content,
        )
        print(f"  ğŸ“ Posted to blog: {filename}")
    except Exception as e:
        if "already exists" in str(e):
            print("  â­ï¸  Already posted, skipping")
        else:
            print(f"  âš ï¸ GitHub error: {e}")


# â”€â”€ Pipeline 1: RSS Feed (22ì¼ ì£¼ê¸°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_rss_pipeline(days_back: int = 22):
    print(f"\n{'='*60}")
    print("ğŸ“¡ [Pipeline 1] RSS Feed Scan")
    print(f"   Scanning last {days_back} days")
    print(f"{'='*60}")

    cutoff = datetime.datetime.now() - datetime.timedelta(days=days_back)
    passed = []

    for journal, url in RSS_FEEDS.items():
        print(f"\n  Fetching: {journal}")
        try:
            feed = feedparser.parse(url)
        except Exception as e:
            print(f"  âš ï¸ RSS error: {e}")
            continue

        for entry in feed.entries:
            pub_date = (
                datetime.datetime(*entry.published_parsed[:6])
                if hasattr(entry, 'published_parsed') and entry.published_parsed
                else datetime.datetime.now()
            )
            if pub_date < cutoff:
                continue

            title    = entry.get('title', '')
            abstract = entry.get('summary', '')
            link     = entry.get('link', '')

            ok, reason = passes_filter(title, abstract)
            if ok:
                passed.append({
                    'title': title, 'abstract': abstract,
                    'link': link, 'journal': journal,
                    'date': pub_date.strftime('%Y-%m-%d'),
                })
                print(f"  âœ… PASS | {reason} | {title[:60]}...")
            else:
                print(f"  â­ï¸  SKIP ({reason})")

    print(f"\n  â†’ {len(passed)} papers passed filters")

    for i, paper in enumerate(passed, 1):
        print(f"\n[{i}/{len(passed)}] {paper['title'][:65]}...")
        try:
            save_to_zotero(paper)
        except Exception as e:
            print(f"  âš ï¸ Zotero error: {e}")

        print("  ğŸ¤– Generating summary...")
        try:
            summary = generate_summary(paper)
        except Exception as e:
            print(f"  âš ï¸ Claude error: {e}")
            continue

        post_to_github(paper, summary, source_label="RSS")
        time.sleep(2)

    print(f"\nâœ… RSS Pipeline done: {len(passed)} papers processed.")
    return len(passed)


# â”€â”€ Pipeline 2: Zotero Queue (ìˆ˜ë™ ì¶”ê°€ë¶„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_zotero_pipeline(days_back: int = 22, debug: bool = False):
    print(f"\n{'='*60}")
    print("ğŸ“š [Pipeline 2] Zotero Queue Scan")
    print(f"   Checking items added in last {days_back} days")
    if debug:
        print("   ğŸ› DEBUG MODE ON")
    print(f"{'='*60}")

    zot     = zotero.Zotero(ZOTERO_USER_ID, 'user', ZOTERO_API_KEY)
    items   = zot.items(sort='dateAdded', direction='desc', limit=50)
    cutoff  = datetime.datetime.now() - datetime.timedelta(days=days_back)
    processed = 0

    for item in items:
        data = item.get('data', {})

        # ê¸°ê°„ ì²´í¬
        date_added = data.get('dateAdded', '')
        if date_added:
            added_dt = datetime.datetime.strptime(date_added[:19], '%Y-%m-%dT%H:%M:%S')
            if added_dt < cutoff:
                continue

        # auto-imported íƒœê·¸ = RSSì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© â†’ ìŠ¤í‚µ
        tags = [t['tag'] for t in data.get('tags', [])]
        if 'auto-imported' in tags:
            if debug:
                print(f"  [DEBUG] SKIP (auto-imported) | {data.get('title','')[:50]}")
            continue

        # blog-posted íƒœê·¸ = ì´ë¯¸ ë¸”ë¡œê·¸ì— ì˜¬ë¦° í•­ëª© â†’ ì¤‘ë³µ ë°©ì§€
        if 'blog-posted' in tags:
            if debug:
                print(f"  [DEBUG] SKIP (blog-posted) | {data.get('title','')[:50]}")
            continue

        title    = data.get('title', '')
        abstract = data.get('abstractNote', '')
        link     = data.get('url', '')
        journal  = data.get('publicationTitle', 'Unknown Journal')
        date     = data.get('date', str(datetime.date.today()))[:10]
        doi      = data.get('DOI', '')

        # abstract ì—†ìœ¼ë©´ DOIë¡œ Crossrefì—ì„œ ìë™ ë³´ì™„
        if not abstract.strip() and doi:
            print(f"  ğŸ” Abstract missing, fetching from Crossref (DOI: {doi})...")
            abstract = fetch_abstract_from_doi(doi)
            if abstract:
                print(f"  âœ… Abstract fetched ({len(abstract)} chars)")

        ok, reason = passes_filter(title, abstract, debug=debug)
        if not ok:
            print(f"  â­ï¸  SKIP ({reason}) | {title[:50]}...")
            continue

        print(f"\n  âœ… MATCH | {reason} | {title[:60]}...")

        paper = {
            'title': title, 'abstract': abstract,
            'link': link, 'journal': journal, 'date': date,
        }

        print("  ğŸ¤– Generating summary...")
        try:
            summary = generate_summary(paper)
        except Exception as e:
            print(f"  âš ï¸ Claude error: {e}")
            continue

        post_to_github(paper, summary, source_label="Zotero")

        # ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ â†’ ë‹¤ìŒ ì‹¤í–‰ ë•Œ ì¤‘ë³µ ë°©ì§€
        try:
            zot.update_item({
                **item,
                'data': {
                    **data,
                    'tags': data.get('tags', []) + [{'tag': 'blog-posted'}],
                }
            })
            print("  ğŸ·ï¸  Tagged 'blog-posted' in Zotero")
        except Exception as e:
            print(f"  âš ï¸ Tag update error: {e}")

        processed += 1
        time.sleep(2)

    print(f"\nâœ… Zotero Pipeline done: {processed} papers processed.")
    return processed


# â”€â”€ Main: ë‘ íŒŒì´í”„ë¼ì¸ í†µí•© ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_all(days_back: int = 22):
    print("\nğŸš€ Starting Literature Automation Pipeline")
    print(f"   Scan window: {days_back} days\n")

    rss_count    = run_rss_pipeline(days_back=days_back)
    zotero_count = run_zotero_pipeline(days_back=days_back)

    print(f"\n{'='*60}")
    print("ğŸ‰ All Done!")
    print(f"   RSS papers posted   : {rss_count}")
    print(f"   Zotero papers posted: {zotero_count}")
    print(f"   Blog: https://soomin-umd.github.io")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    run_all(days_back=22)
